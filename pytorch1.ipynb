{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeiniz/StatML/blob/main/pytorch1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcJK3kXl--c3"
      },
      "source": [
        "# 통계적기계학습 (숙명여대 통계학과 2024-1) lec 02 : PyTorch 101\n",
        "\n",
        "\n",
        "**Acknowledgement** 본 강의노트는 원작자의 허가 하에 다음 강좌의 강의노트를 일부 수정 or 번역함 :\n",
        "\n",
        "Justin Johnson, *Deep Learning for Computer Vision*, University of Michigan EECS 498-007 / 598-005.\n",
        "\n",
        "본 실습 강의노트는 원 강의에서 Assignment 1-2 (A1-2)에 해당합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc83ETI1a3o9"
      },
      "source": [
        "# 1. 소개\n",
        "\n",
        "Python 3 및 [PyTorch](https://pytorch.org/)는 학기 내내 사용되므로 익숙해지는 것이 중요합니다. 이 노트북의 자료의 출처는 http://cs231n.github.io/python-numpy-tutorial/ 및 https://github.com/kuleshov/cs228-material/blob/master/tutorials/python/cs228-python-tutorial.ipynb 입니다. 이 자료는 주로 PyTorch에 중점을 둡니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRwiu2K93KUC"
      },
      "source": [
        "### 1.1. Google Colab (구글 코랩)\n",
        "\n",
        "Google Colaboratory는 클라우드 기반의 Python 3 (iPython Notebook) 개발환경(IDE) 이다.\n",
        "\n",
        "코랩를 사용하면 구글이 무료로 제공하는 클라우드 가상머신 위에서 Python 코드를 개발할 수 있다. 또한 Python 기반의 기계학습 라이브러리들이 (PyTorch, TensorFlow 포함) 이미 가상머신에 설치되어 있어 기계학습 실습을 쉽게 할 수 있다.\n",
        "\n",
        "단 **리소스 제한**이 존재한다. 90분간 코드 실행이 없으면 자동으로 세션이 종료된다 (가상머신이 초기화됨). 연속하여 12시간 구동하면 또한 세션이 종료된다. 월 9.99달러의 구독료를 내면 세션이 더 오래 지속되고 더 고성능 GPU를 사용할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MEmHrgBsgX4"
      },
      "source": [
        "# 2. PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3e_Nux0siHo"
      },
      "source": [
        "\n",
        "[파이토치(PyTorch)](https://pytorch.org/)는 기계학습을 위한 오픈소스 프레임워크이다. 파이토치의 핵심 기능은 다음과 같다:\n",
        "\n",
        "- 다차원의 **텐서(tensor)** 객체를 지원한다. 파이토치의 텐서 객체는 [numpy](https://numpy.org/)의 텐서 객체와 비슷하나, 추가적으로 ***GPU 가속***을 지원한다!\n",
        "- 최적화된 **autograd** 엔진이 내장되어 있어 미분값을 자동적으로 계산해준다.\n",
        "- **딥러닝 모델**을 빌드하고 배포하는 과정에 필요한 API 및 코드들이 깔끔하면서도 모듈화되어 있다.\n",
        "\n",
        "이번학기동안 파이토치가 모든 프로그래밍 숙제에 사용된다. 이 노트북 파일은 **텐서 API**에 초점이 맞추어져 있는데, 최초 몇 숙제들을 수행하기 위해 숙지할 필요가 있다.\n",
        "\n",
        "파이토치에 대한 더 자세한 정보는 [공식 튜토리얼](https://pytorch.org/tutorials/) 이나  [공식 매뉴얼](https://pytorch.org/docs/1.1.0/)을 참조하라."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdiO3_y-vKQ9"
      },
      "source": [
        "파이토치 사용을 위하여는 먼저 `torch` 패키지를 임포트하여야 한다.\n",
        "\n",
        "버전 체크도 필요하다. 이번 강의에서는 구글 코랩의 디폴트 버전인 2.1.0 (2024년 3월 12일 현재)을 사용할 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sydFm14itrqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8973574-e4d9-4be3-9823-6aa95484a334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrBSx6hYu8ca"
      },
      "source": [
        "## 2.1. Tensor Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWagwmXuvIle"
      },
      "source": [
        "### Creating and Accessing tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf_SY4RzvAh_"
      },
      "source": [
        "`torch` **tensor**는 모두 같은 유형의 값으로 구성된 다차원 grid이며 음이 아닌 정수 tuple에 의해 인덱싱됩니다. 차원은 텐서의 **rank**입니다. 텐서의 **크기**는 각 차원을 따라 배열의 크기를 제공하는 정수 tuple입니다.\n",
        "\n",
        "중첩된 Python 리스트에서 `torch` 텐서를 초기화할 수 있습니다. 대괄호를 사용하여 PyTorch tensor의 원소에 접근하거나 원소를 변경할 수 있습니다.\n",
        "\n",
        "PyTorch tensor에서 원소에 접근하면 PyTorch 스칼라가 반환됩니다. `.item()` 메소드를 사용하여 이것을 Python 스칼라로 변환할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([1,2,3])\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0ERCn02SytX",
        "outputId": "67d795e9-1f81-4a51-d886-f9004e828543"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IpwfVUvPu_lF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06c38925-50a2-4f9a-eea0-f0919a40e3f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a:\n",
            "tensor([1, 2, 3])\n",
            "type(a):  <class 'torch.Tensor'>\n",
            "rank of a:  1\n",
            "a.shape:  torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "# Create a rank 1 tensor from a Python list\n",
        "a = torch.tensor([1, 2, 3])\n",
        "print('Here is a:')\n",
        "print(a)\n",
        "print('type(a): ', type(a))\n",
        "print('rank of a: ', a.dim())  #  1\n",
        "print('a.shape: ', a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KcJ0sGORhWRW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a9f0fd0-9c35-416e-f72e-9783b8bb0293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a[0]:  tensor(1)\n",
            "type(a[0]):  <class 'torch.Tensor'>\n",
            "type(a[0].item()):  <class 'int'>\n"
          ]
        }
      ],
      "source": [
        "# Access elements using square brackets\n",
        "print('a[0]: ', a[0])\n",
        "print('type(a[0]): ', type(a[0]))\n",
        "print('type(a[0].item()): ', type(a[0].item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7T99IQgnhWRW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd1197d-52f4-44ac-9ad0-9cf51bea59d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a after mutating:\n",
            "tensor([ 1, 10,  3])\n"
          ]
        }
      ],
      "source": [
        "# Mutate elements using square brackets\n",
        "a[1] = 10\n",
        "print('a after mutating:')\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZq4zsnLEgXH"
      },
      "source": [
        "위의 예제는 1차원 tensor를 보여줍니다; 비슷한 방식으로 2차원 또는 다차원의 tensors를 생성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7TcvHxpTFUcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dceb013-ed5d-4f18-9958-710b690a584b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is b:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 5]])\n",
            "rank of b: 2\n",
            "b.shape:  torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "# Create a two-dimensional tensor\n",
        "b = torch.tensor([[1, 2, 3], [4, 5, 5]])\n",
        "print('Here is b:')\n",
        "print(b)\n",
        "print('rank of b:', b.dim())\n",
        "print('b.shape: ', b.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vUwjVftThWRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6792925-b98f-40c9-8ac3-f241f9386372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b[0, 1]: tensor(2)\n",
            "b[1, 2]: tensor(5)\n"
          ]
        }
      ],
      "source": [
        "# Access elements from a multidimensional tensor\n",
        "print('b[0, 1]:', b[0, 1])\n",
        "print('b[1, 2]:', b[1, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PUoEH7oLhWRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f711a38-34fc-4a79-b6b9-4ac16b8fc8c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b after mutating:\n",
            "tensor([[  1,   2,   3],\n",
            "        [  4, 100,   5]])\n"
          ]
        }
      ],
      "source": [
        "# Mutate elements of a multidimensional tensor\n",
        "b[1, 1] = 100\n",
        "print('b after mutating:')\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz_VDA3IvP33"
      },
      "source": [
        "### Tensor constructors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoAlslEdwV-k"
      },
      "source": [
        "PyTorch는 Tensor를 생성할 수 있는 편리한 방법을 많이 제공합니다. 이렇게 하면 Python 리스트를 사용할 필요가 없습니다. 예시:\n",
        "\n",
        "- [`torch.zeros`](https://pytorch.org/docs/1.1.0/torch.html#torch.zeros): 모든 원소가 0인 tensor 생성\n",
        "- [`torch.ones`](https://pytorch.org/docs/1.1.0/torch.html#torch.ones): 모든 원소가 1인 tensor 생성\n",
        "- [`torch.rand`](https://pytorch.org/docs/1.1.0/torch.html#torch.rand): 균등 난수로 구성된 tensor 생성\n",
        "\n",
        "tensor 생성 작업의 전체 목록은 [문서에서](https://pytorch.org/docs/1.1.0/torch.html#creation-ops) 찾을 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FL6DXGXzxHBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8e80bc-de79-4142-d209-6c2db25f544d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor of zeros:\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor of all zeros\n",
        "a = torch.zeros(2, 3)\n",
        "print('tensor of zeros:')\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_1LQKwDZhWRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4da389-f400-4286-dc52-ff27bdb47999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor of ones:\n",
            "tensor([[1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor of all ones\n",
        "b = torch.ones(1, 2)\n",
        "print('tensor of ones:')\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oPScfQdphWRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b24680-75ab-475a-b5d3-5ef0c1ba2126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "identity matrix:\n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# Create a 3x3 identity matrix\n",
        "c = torch.eye(3)\n",
        "print('identity matrix:')\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DV7vj5QEhWRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "447fdcbc-7df1-4c2b-e76d-cfc34ebeef56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random tensor:\n",
            "tensor([[0.0889, 0.9399, 0.6059, 0.9930, 0.9032],\n",
            "        [0.1911, 0.5141, 0.7438, 0.3100, 0.6764],\n",
            "        [0.0109, 0.9375, 0.2784, 0.9717, 0.8029],\n",
            "        [0.5372, 0.5776, 0.1819, 0.2846, 0.8872]])\n"
          ]
        }
      ],
      "source": [
        "# Tensor of random values\n",
        "d = torch.rand(4, 5)\n",
        "print('random tensor:')\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlANfnILvX3S"
      },
      "source": [
        "## 2.2. Tensor indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP4dRrHhyLO5"
      },
      "source": [
        "우리는 이미 PyTorch 텐서의 개별 원소를 가져오고 설정하는 방법을 살펴보았습니다. PyTorch는 텐서로 색인을 생성하는 다른 많은 방법도 제공합니다. 이러한 다양한 옵션에 익숙해지면 텐서의 다른 부분을 쉽게 수정할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo-PoTWNvbba"
      },
      "source": [
        "### Slice indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUqTYvglyVLc"
      },
      "source": [
        "Python 리스트 및 numpy 배열과 유사하게 PyTorch 텐서는 `start:stop` 또는 `start:stop:step` 구문을 사용하여 **슬라이싱**할 수 있습니다. `stop` 인덱스는 항상 포함되지 않으며 슬라이스에 포함되지 않는 첫 번째 요소입니다.\n",
        "\n",
        "시작 및 중지 인덱스는 음수일 수 있으며, 이 경우 텐서의 끝에서 거꾸로 계산됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yEr5BzdUdCtZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af9de388-fd07-4e8e-ddd5-50e27a158128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor([ 0, 11, 22, 33, 44, 55, 66])\n",
            "1 tensor([22, 33, 44])\n",
            "2 tensor([22, 33, 44, 55, 66])\n",
            "3 tensor([ 0, 11, 22, 33, 44])\n",
            "4 tensor([ 0, 11, 22, 33, 44, 55, 66])\n",
            "5 tensor([11, 33])\n",
            "6 tensor([ 0, 11, 22, 33, 44, 55])\n",
            "7 tensor([33, 55])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([0, 11, 22, 33, 44, 55, 66])\n",
        "print(0, a)        # (0) Original tensor\n",
        "print(1, a[2:5])   # (1) Elements between index 2 and 5 (2, 3, 4번째 elements)\n",
        "print(2, a[2:])    # (2) Elements after index 2\n",
        "print(3, a[:5])    # (3) Elements before index 5\n",
        "print(4, a[:])     # (4) All elements\n",
        "print(5, a[1:5:2]) # (5) Every second element between indices 1 and 5 (1번째, 3번째)\n",
        "print(6, a[:-1])   # (6) All but the last element --> a[:-2], a[-2:]도 해 보세요.\n",
        "print(7, a[-4::2]) # (7) Every second element, starting from the fourth-last"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrcr9PojgTS1"
      },
      "source": [
        "다차원 텐서의 경우 다른 유형의 하위 텐서를 추출하기 위해 텐서의 각 차원에 대해 슬라이스 또는 정수를 제공할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "S5fOdjTUyhNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cadccce5-9820-4b11-c9ca-a4f9b4fd8be7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "shape:  torch.Size([3, 4])\n"
          ]
        }
      ],
      "source": [
        "# Create the following rank 2 tensor with shape (3, 4)\n",
        "# [[ 1  2  3  4]\n",
        "#  [ 5  6  7  8]\n",
        "#  [ 9 10 11 12]]\n",
        "a = torch.tensor([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
        "print('Original tensor:')\n",
        "print(a)\n",
        "print('shape: ', a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kBQob7q1hWRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82481d98-78ea-4348-805f-227d3e89e09e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single row:\n",
            "tensor([5, 6, 7, 8])\n",
            "tensor([5, 6, 7, 8])\n",
            "shape:  torch.Size([4])\n"
          ]
        }
      ],
      "source": [
        "# Get row 1, and all columns.\n",
        "print('Single row:')\n",
        "print(a[1, :])\n",
        "# * 주 : R에서처럼 a[ ,1] 입력하면 에러남. --> a[:, 1]\n",
        "print(a[1])  # Gives the same result; we can omit : for trailing dimensions\n",
        "print('shape: ', a[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aDx51DtshWRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13258369-02d6-4285-914e-962d4e90b3c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single column:\n",
            "tensor([ 2,  6, 10])\n",
            "shape:  torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "print('Single column:')\n",
        "print(a[:, 1])\n",
        "print('shape: ', a[:, 1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wnv22iF4hWRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea346c07-cee2-41eb-e8d5-6345715510ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First two rows, last two columns:\n",
            "tensor([[2, 3, 4],\n",
            "        [6, 7, 8]])\n",
            "shape:  torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "# Get the first two rows and the last three columns\n",
        "print('First two rows, last two columns:')\n",
        "print(a[:2, -3:])\n",
        "print('shape: ', a[:2, -3:].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOsR8Pdertku"
      },
      "source": [
        "텐서의 단일 행이나 열에 접근하는 두 가지 일반적인 방법이 있습니다. 정수를 사용하면 rank가 1 감소하고 길이가 1인 슬라이스를 사용하면 동일한 rank가 유지됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "P1kHcc5jsF-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008562a1-565e-4a02-cbf9-574bfe003d14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "\n",
            "Two ways of accessing a single row:\n",
            "tensor([5, 6, 7, 8]) torch.Size([4])\n",
            "tensor([[5, 6, 7, 8]]) torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "# Create the following rank 2 tensor with shape (3, 4)\n",
        "a = torch.tensor([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
        "print('Original tensor')\n",
        "print(a)\n",
        "\n",
        "row_r1 = a[1, :]    # Rank 1 view of the second row of a\n",
        "row_r2 = a[1:2, :]  # Rank 2 view of the second row of a\n",
        "print('\\nTwo ways of accessing a single row:')\n",
        "print(row_r1, row_r1.shape)\n",
        "print(row_r2, row_r2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "d5XMd9NDhWRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b06ce94e-d5ef-42d3-93c4-851b4a9f0894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Two ways of accessing a single column:\n",
            "tensor([ 2,  6, 10]) torch.Size([3])\n",
            "tensor([[ 2],\n",
            "        [ 6],\n",
            "        [10]]) torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "# We can make the same distinction when accessing columns::\n",
        "col_r1 = a[:, 1]\n",
        "col_r2 = a[:, 1:2]\n",
        "print('Two ways of accessing a single column:')\n",
        "print(col_r1, col_r1.shape)\n",
        "print(col_r2, col_r2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk625fJfyxV8"
      },
      "source": [
        "**중요.** 텐서를 슬라이싱하면 **view**가 동일한 데이터로 리턴되므로 수정하면 원래 텐서도 수정됩니다. 이를 피하기 위해 `clone()` 메서드를 사용하여 텐서의 복사본을 만들 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IXbikYPwyxGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63fc2b5a-fdd0-4fed-ed60-90af71aacbc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before mutating:\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "tensor([2, 3, 4])\n",
            "tensor([2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor, a slice, and a clone of a slice\n",
        "a = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "b = a[0, 1:] # a[0, 1:]와 b는 메모리상의 같은 객체를 지칭하고 있음. (따라서 b의 변경에 따라 a도 바뀜)\n",
        "c = a[0, 1:].clone()  # 메모리에서 a[0, 1:]의 사본을 만든 뒤 그것을 c가 가리키게 함.\n",
        "print('Before mutating:')\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XJwwBZuuhWRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab497c6-04d1-49af-ede4-be026e0ca499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1, 20,  3,  4],\n",
            "        [ 5,  6,  7,  8]])\n",
            "tensor([20,  3,  4])\n",
            "tensor([2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "a[0, 1] = 20  # a[0, 1] and b[0] point to the same element\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UrYw7wnihWRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac51b8eb-5af5-4cd4-8c5f-9e336a0e29be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1, 20, 30,  4],\n",
            "        [ 5,  6,  7,  8]])\n",
            "tensor([20, 30,  4])\n",
            "tensor([2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "b[1] = 30     # b[1] and a[0, 2] point to the same element\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8Yx3wbYahWRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65d77019-4102-4dcf-ec55-fc04d8402986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After mutating:\n",
            "tensor([[ 1, 20, 30,  4],\n",
            "        [ 5,  6,  7,  8]])\n",
            "tensor([20, 30,  4])\n",
            "tensor([ 2,  3, 40])\n"
          ]
        }
      ],
      "source": [
        "c[2] = 40     # c is a clone, so it has its own data\n",
        "print('\\nAfter mutating:')\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNjhLwb0xY2A"
      },
      "source": [
        "지금까지 우리는 슬라이싱을 사용하여 서브텐서에 **접근**했습니다. 왼쪽이 슬라이스 표현식이고 오른쪽이 올바른 크기의 상수 또는 텐서인 할당 표현식을 작성하는 것으로 슬라이싱을 사용하여 서브텐서를 **수정**할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DFnky42Rx2I5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3007b4b6-b858-4e45-ce9e-0aca683538dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0, 0],\n",
            "        [0, 0, 0, 0]])\n",
            "tensor([[1, 1, 2, 3],\n",
            "        [1, 1, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.zeros(2, 4, dtype=torch.int64)\n",
        "print(a)\n",
        "a[:, :2] = 1\n",
        "a[:, 2:] = torch.tensor([[2, 3], [4, 5]])\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y93rPhGveWw"
      },
      "source": [
        "### Integer tensor indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlTyhjEN0AIE"
      },
      "source": [
        "슬라이싱을 사용하여 torch 텐서를 인덱스할 때, 텐서 view의 결과는 항상 원래 텐서의 하위 배열이 됩니다. 이것은 강력하지만 제한적일 수 있습니다.\n",
        "\n",
        "**index arrays**을 사용하여 텐서를 인덱스할 수 있습니다. 이를 통해 슬라이스를 사용하는 것보다 훨씬 더 유연하게 새로운 텐서를 생성할 수 있습니다.\n",
        "\n",
        "예를 들어, index arrays을 사용하여 텐서의 행이나 열을 재정렬할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "IXePPNkjM_SD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95dd4397-d396-4b69-df1a-3eba7a892cc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "\n",
            "Reordered rows:\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 1,  2,  3,  4],\n",
            "        [ 9, 10, 11, 12],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 5,  6,  7,  8]])\n",
            "\n",
            "Reordered columns:\n",
            "tensor([[ 4,  3,  2,  1],\n",
            "        [ 8,  7,  6,  5],\n",
            "        [12, 11, 10,  9]])\n"
          ]
        }
      ],
      "source": [
        "# Chunk 2.2.9.\n",
        "\n",
        "# Create the following rank 2 tensor with shape (3, 4)\n",
        "# [[ 1  2  3  4]\n",
        "#  [ 5  6  7  8]\n",
        "#  [ 9 10 11 12]]\n",
        "a = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
        "print('Original tensor:')\n",
        "print(a)\n",
        "\n",
        "# Create a new tensor of shape (5, 4) by reordering rows from a:\n",
        "# - First two rows same as the first row of a\n",
        "# - Third row is the same as the last row of a\n",
        "# - Fourth and fifth rows are the same as the second row from a\n",
        "idx = [0, 0, 2, 1, 1]  # index arrays can be Python lists of integers\n",
        "print('\\nReordered rows:')\n",
        "print(a[idx])\n",
        "\n",
        "# Create a new tensor of shape (3, 4) by reversing the columns from a\n",
        "idx = torch.tensor([3, 2, 1, 0])  # Index arrays can be int64 torch tensors\n",
        "print('\\nReordered columns:')\n",
        "print(a[:, idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpIBR1bCQji6"
      },
      "source": [
        "더 일반적으로 인덱스 배열 `idx0` 및 `idx1`에 각각 `N` 개의 원소가 있는 경우, `a[idx0, idx1]`는 다음과 같습니다.\n",
        "\n",
        "```\n",
        "torch.tensor([\n",
        "  a[idx0[0], idx1[0]],\n",
        "  a[idx0[1], idx1[1]],\n",
        "  ...,\n",
        "  a[idx0[N - 1], idx1[N - 1]]\n",
        "])\n",
        "```\n",
        "\n",
        "(이러한 유사한 패턴은 2차원 이상의 텐서로 확장됩니다)\n",
        "\n",
        "예를 들어 이것을 사용하여 텐서의 대각선을 얻거나 세팅할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ocIR8R5ZSEaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ada272ed-eb03-4953-940a-d3de7f9b5a9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "\n",
            "Get the diagonal:\n",
            "tensor([1, 5, 9])\n",
            "\n",
            "After setting the diagonal:\n",
            "tensor([[11,  2,  3],\n",
            "        [ 4, 22,  6],\n",
            "        [ 7,  8, 33]])\n"
          ]
        }
      ],
      "source": [
        "# Chunk 2.2.10.\n",
        "\n",
        "a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "print('Original tensor:')\n",
        "print(a)\n",
        "\n",
        "idx = [0, 1, 2]\n",
        "print('\\nGet the diagonal:')\n",
        "print(a[idx, idx])   # a[0,0] a[1,1] a[2,2]\n",
        "\n",
        "# * 주의. R의 행렬에서도 에서도 a[idx, idx] 식의 문법을 지원하나 결과가 다름.\n",
        "\n",
        "# Modify the diagonal\n",
        "a[idx, idx] = torch.tensor([11, 22, 33])\n",
        "print('\\nAfter setting the diagonal:')\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "HWA8E8iI0x17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852fc44c-9d13-4f1e-a328-e8022c8ed7f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            "tensor([[ 1,  2,  3],\n",
            "        [ 4,  5,  6],\n",
            "        [ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "\n",
            "Select one element from each row:\n",
            "tensor([ 2,  6,  8, 10])\n",
            "\n",
            "After modifying one element from each row:\n",
            "tensor([[ 1,  0,  3],\n",
            "        [ 4,  5,  0],\n",
            "        [ 7,  0,  9],\n",
            "        [ 0, 11, 12]])\n"
          ]
        }
      ],
      "source": [
        "# Create a new tensor from which we will select elements\n",
        "a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
        "print('Original tensor:')\n",
        "print(a)\n",
        "\n",
        "# Take on element from each row of a:\n",
        "# from row 0, take element 1;\n",
        "# from row 1, take element 2;\n",
        "# from row 2, take element 1;\n",
        "# from row 3, take element 0\n",
        "idx0 = torch.arange(4)  # Quick way to build [0, 1, 2, 3]\n",
        "idx1 = torch.tensor([1, 2, 1, 0])\n",
        "print('\\nSelect one element from each row:')\n",
        "print(a[idx0, idx1])\n",
        "\n",
        "# Now set each of those elements to zero\n",
        "a[idx0, idx1] = 0\n",
        "print('\\nAfter modifying one element from each row:')\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGt8ZPb_vixw"
      },
      "source": [
        "### Boolean tensor indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CkQaRj01xmU"
      },
      "source": [
        "Boolean 텐서 인덱싱을 사용하면 Boolean mask에 따라 텐서의 임의 요소를 선택할 수 있습니다. 종종 이러한 유형의 인덱싱은 일부 조건을 충족하는 텐서의 원소를 선택하거나 수정하는 데 사용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "29Zf7rb82Dkd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c63d75-df31-4f1c-bbd7-f419e9238761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n",
            "Mask tensor:\n",
            "tensor([[False, False],\n",
            "        [False,  True],\n",
            "        [ True,  True]])\n"
          ]
        }
      ],
      "source": [
        "# Chunk 2.2.12.\n",
        "\n",
        "a = torch.tensor([[1,2], [3, 4], [5, 6]])\n",
        "print('Original tensor:')\n",
        "print(a)\n",
        "\n",
        "# Find the elements of a that are bigger than 3. The mask has the same shape as\n",
        "# a, where each element of mask tells whether the corresponding element of a\n",
        "# is greater than three.\n",
        "mask = (a > 3)\n",
        "print('\\nMask tensor:')\n",
        "print(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Vzdoj1GEhWRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6056325-099d-47d2-8216-eb940681fc10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting elements with the mask:\n",
            "tensor([4, 5, 6])\n",
            "\n",
            "After modifying with a mask:\n",
            "tensor([[0, 0],\n",
            "        [0, 4],\n",
            "        [5, 6]])\n"
          ]
        }
      ],
      "source": [
        "# We can use the mask to construct a rank-1 tensor containing the elements of a\n",
        "# that are selected by the mask\n",
        "print('Selecting elements with the mask:')\n",
        "print(a[mask])\n",
        "\n",
        "# We can also use boolean masks to modify tensors; for example this sets all\n",
        "# elements <= 3 to zero:\n",
        "a[a <= 3] = 0\n",
        "print('\\nAfter modifying with a mask:')\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad-xqELwyqpN"
      },
      "source": [
        "## 2.3. Reshaping operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql9_eXuU4OG8"
      },
      "source": [
        "### Reshape opertations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfPb_2BY0HKw"
      },
      "source": [
        "PyTorch는 텐서의 크기를 조작하는 다양한 방법을 제공합니다. 가장 간단한 예는 [`.reshape()`](https://pytorch.org/docs/1.1.0/tensors.html#torch.Tensor.reshape)입니다. 입력과 같은 개수의 원소지만 크기가 다른 새 텐서를 반환합니다.\n",
        "\n",
        "\n",
        "\n",
        "`.reshape()`를 사용하여 행렬을 벡터로 만들고 rank 1 벡터를 rank 2 행 또는 열 행렬로 변환할 수 있습니다. (크기가 맞아야 실행 가능)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "kw-M7C_61FZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "739b95bd-ab46-49e6-c302-46cc20203ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "shape: torch.Size([2, 4])\n",
            "\n",
            "Flattened tensor:\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
            "shape: torch.Size([8])\n",
            "\n",
            "Row vector:\n",
            "tensor([[1, 2, 3, 4, 5, 6, 7, 8]])\n",
            "shape: torch.Size([1, 8])\n"
          ]
        }
      ],
      "source": [
        "x0 = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "print('Original tensor:')\n",
        "print(x0)\n",
        "print('shape:', x0.shape)\n",
        "\n",
        "# Flatten x0 into a rank 1 vector of shape (8,)\n",
        "x1 = x0.reshape(8)\n",
        "print('\\nFlattened tensor:')\n",
        "print(x1)\n",
        "print('shape:', x1.shape)\n",
        "\n",
        "# Convert x1 to a rank 2 \"row vector\" of shape (1, 8)\n",
        "x2 = x1.reshape(1, 8)\n",
        "print('\\nRow vector:')\n",
        "print(x2)\n",
        "print('shape:', x2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "bbvYvJgFhWRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19fb390c-00f3-424f-855b-813e18b3387e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column vector:\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [5],\n",
            "        [6],\n",
            "        [7],\n",
            "        [8]])\n",
            "shape: torch.Size([8, 1])\n"
          ]
        }
      ],
      "source": [
        "# Convert x1 to a rank 2 \"column vector\" of shape (8, 1)\n",
        "x3 = x1.reshape(8, 1)\n",
        "print('Column vector:')\n",
        "print(x3)\n",
        "print('shape:', x3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "4omK219JhWRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0301d7d-0a2f-4151-9644-b652e322a3b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank 3 tensor:\n",
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n",
            "shape: torch.Size([2, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "# Convert x1 to a rank 3 tensor of shape (2, 2, 2):\n",
        "x4 = x1.reshape(2, 2, 2)\n",
        "print('Rank 3 tensor:')\n",
        "print(x4)\n",
        "print('shape:', x4.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHsZ8BPF2PEq"
      },
      "source": [
        "편의상 `.reshape()`에 대한 호출에는 -1 인수가 포함될 수 있습니다. 이렇게 하면 출력이 입력과 같은 크기가 되도록 해당 차원에 충분한 원소가 배치됩니다. 이렇게 하면 텐서의 크기에 구애받지 않는 방식으로 크기 변경 연산을 쉽게 할 수 있습니다. (나누어 떨어지는 경우만 가능)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "qNWu-R_J2qFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06dfd902-8936-4857-b97d-eb4a9db75249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x0:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "x0_flat:\n",
            "tensor([1, 2, 3, 4, 5, 6])\n",
            "x0_row:\n",
            "tensor([[1, 2, 3, 4, 5, 6]])\n"
          ]
        }
      ],
      "source": [
        "# Chunk 2.3.2.\n",
        "x0 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "x0_flat = x0.reshape(-1)\n",
        "x0_row = x0.reshape(1, -1)\n",
        "print('x0:')\n",
        "print(x0)\n",
        "print('x0_flat:')\n",
        "print(x0_flat)\n",
        "print('x0_row:')\n",
        "print(x0_row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "5aybcBMXhWRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc5908e-b0d5-4c44-f694-c6f704fb255d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1:\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "x1_flat:\n",
            "tensor([1, 2, 3, 4])\n",
            "x1_row:\n",
            "tensor([[1, 2, 3, 4]])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.tensor([[1, 2], [3, 4]])\n",
        "x1_flat = x1.reshape(-1)\n",
        "x1_row = x1.reshape(1, -1)\n",
        "print('x1:')\n",
        "print(x1)\n",
        "print('x1_flat:')\n",
        "print(x1_flat)\n",
        "print('x1_row:')\n",
        "print(x1_row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z150qBob4Wkz"
      },
      "source": [
        "### Swapping axes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCMDxbyBys78"
      },
      "source": [
        "스스로 시도해볼 수 있는 또 다른 일반적인 크기 변경 연산은 행렬을 전치하는 것입니다. `.reshape()`로 행렬을 전치하려고 하면 당황할 수 있습니다. `reshape()` 함수는 행 우선 순위로 원소를 취하므로 **`.reshape()`로 행렬을 전치할 수 없습니다.**\n",
        "\n",
        "* 부가설명: 예를 들어 shape (2,2,2) tensor를 `.reshape`를 통하여 shape (4,2) tensor로 변환하면, 다음 순서에 따라 성분들이 재배정됨 :\n",
        "```\n",
        "[0,0,0] 번째 성분 --> [0,0]번째 성분\n",
        "[0,0,1] 번째 성분 --> [0,1]번째 성분\n",
        "[0,1,0] 번째 성분 --> [1,0]번째 성분\n",
        "[0,1,1] 번째 성분 --> [1,1]번째 성분\n",
        "[1,0,0] 번째 성분 --> [2,0]번째 성분\n",
        "...\n",
        "```\n",
        "따라서 텐서의 축을 바꿀 수 있는 함수를 사용해야 합니다. 가장 단순한 함수는 특별히 행렬을 전치하기 위해 사용하는 `.t()`입니다. [function in the `torch` module](https://pytorch.org/docs/1.1.0/torch.html#torch.t)과 [tensor instance method](https://pytorch.org/docs/1.1.0/tensors.html#torch.Tensor.t) 에서 모두 가능합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "o_B4NuX6zQm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d1fc051-47a7-4e51-d578-c87beac734f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original matrix:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "Transposing with view DOES NOT WORK!\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n",
            "Transposed matrix:\n",
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n",
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n"
          ]
        }
      ],
      "source": [
        "# Chunk 2.3.4.\n",
        "\n",
        "# 복붙\n",
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print('Original matrix:')\n",
        "print(x)\n",
        "print('\\nTransposing with view DOES NOT WORK!')\n",
        "print(x.reshape(3, 2))\n",
        "print('\\nTransposed matrix:')\n",
        "print(torch.t(x))\n",
        "print(x.t())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgcdvD1evxTQ"
      },
      "source": [
        "## 2.4. Tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BCVlPHZ4_Qz"
      },
      "source": [
        "### Elementwise operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2wbN18E5CKI"
      },
      "source": [
        "기본 수학 함수는 텐서에서 **원소별로** 작동하고, 연산자 오버로드(예: `x - y`)와 `torch` 모듈의 함수(예: `torch.add(x,y)`), 그리고 torch 객체의 인스턴스 메소드(예. `x.add.y`)에 가능합니다. 모두 동일한 결과를 생성합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "QrMkbk535KRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e8288da-31b4-40ff-987c-61d10939265e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elementwise sum:\n",
            "tensor([[ 6.,  8., 10., 12.]])\n",
            "tensor([[ 6.,  8., 10., 12.]])\n",
            "tensor([[ 6.,  8., 10., 12.]])\n",
            "\n",
            "Elementwise difference:\n",
            "tensor([[-4., -4., -4., -4.]])\n",
            "tensor([[-4., -4., -4., -4.]])\n",
            "tensor([[-4., -4., -4., -4.]])\n",
            "\n",
            "Elementwise product:\n",
            "tensor([[ 5., 12., 21., 32.]])\n",
            "tensor([[ 5., 12., 21., 32.]])\n",
            "tensor([[ 5., 12., 21., 32.]])\n",
            "\n",
            "Elementwise division\n",
            "tensor([[0.2000, 0.3333, 0.4286, 0.5000]])\n",
            "tensor([[0.2000, 0.3333, 0.4286, 0.5000]])\n",
            "tensor([[0.2000, 0.3333, 0.4286, 0.5000]])\n",
            "\n",
            "Elementwise power\n",
            "tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])\n",
            "tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])\n",
            "tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])\n"
          ]
        }
      ],
      "source": [
        "# Chunk 2.4.1.\n",
        "\n",
        "x = torch.tensor([[1, 2, 3, 4]], dtype=torch.float32)\n",
        "y = torch.tensor([[5, 6, 7, 8]], dtype=torch.float32)\n",
        "\n",
        "# * Operator overload만 해봅니다.\n",
        "\n",
        "# Elementwise sum; all give the same result\n",
        "print('Elementwise sum:')\n",
        "print(x + y)\n",
        "print(torch.add(x, y))\n",
        "print(x.add(y))\n",
        "\n",
        "# Elementwise difference\n",
        "print('\\nElementwise difference:')\n",
        "print(x - y)\n",
        "print(torch.sub(x, y))\n",
        "print(x.sub(y))\n",
        "\n",
        "# Elementwise product\n",
        "print('\\nElementwise product:')\n",
        "print(x * y)\n",
        "print(torch.mul(x, y))\n",
        "print(x.mul(y))\n",
        "\n",
        "# Elementwise division\n",
        "print('\\nElementwise division')\n",
        "print(x / y)\n",
        "print(torch.div(x, y))\n",
        "print(x.div(y))\n",
        "\n",
        "# Elementwise power\n",
        "print('\\nElementwise power')\n",
        "print(x ** y)\n",
        "print(torch.pow(x, y))\n",
        "print(x.pow(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6WwPJMYlYvN"
      },
      "source": [
        "Torch는 또한 많은 표준 수학 함수를 제공합니다. `torch` 모듈의 함수(예: `torch.sqrt(x)`)와 텐서의 인스턴스 메소드(예: `x.sqrt()`)로 사용할 수 있습니다.\n",
        "\n",
        "사용 가능한 모든 수학 함수의 전체 목록은 [문서에서](https://pytorch.org/docs/stable/torch.html#pointwise-ops) 찾을 수 있습니다. `torch` 모듈의 많은 함수에는 [tensor 객체](https://pytorch.org/docs/stable/tensors.html)에 대한 동일한 인스턴스 메소드가 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "s87mjsnG58vR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3973f4db-b7e6-4df9-cb44-ef54476b6615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Square root:\n",
            "tensor([[1.0000, 1.4142, 1.7321, 2.0000]])\n",
            "tensor([[1.0000, 1.4142, 1.7321, 2.0000]])\n",
            "\n",
            "Trig functions:\n",
            "tensor([[ 0.8415,  0.9093,  0.1411, -0.7568]])\n",
            "tensor([[ 0.8415,  0.9093,  0.1411, -0.7568]])\n",
            "tensor([[ 0.5403, -0.4161, -0.9900, -0.6536]])\n",
            "tensor([[ 0.5403, -0.4161, -0.9900, -0.6536]])\n"
          ]
        }
      ],
      "source": [
        "# Chunk 2.4.2.\n",
        "\n",
        "# 복붙\n",
        "x = torch.tensor([[1, 2, 3, 4]], dtype=torch.float32)\n",
        "\n",
        "print('Square root:')\n",
        "print(torch.sqrt(x))\n",
        "print(x.sqrt())\n",
        "\n",
        "print('\\nTrig functions:')\n",
        "print(torch.sin(x))\n",
        "print(x.sin())\n",
        "print(torch.cos(x))\n",
        "print(x.cos())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDyH9USAuyZ-"
      },
      "source": [
        "### Reduction operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbHP9SpZHoMO"
      },
      "source": [
        "지금까지 원소별로 작동하는 텐서에 대한 기본적인 산술 연산을 살펴보았습니다. 우리는 때때로 합계와 같이 **텐서의 일부 또는 전체에 대해 집계**하는 작업을 수행하고자 할 수 있습니다. 이를 **reduction** 연산이라고 합니다. (예. 평균, 중앙값, 최댓값, ...)\n",
        "\n",
        "위의 원소별 연산과 마찬가지로 대부분의 reduction 연산은 `torch` 모듈의 함수(예: `torch.sum(x)`)와 `tensor` 객체의 인스턴스 메서드(예. `x.sum() `)에서 모두 가능합니다.\n",
        "\n",
        "가장 간단한 reduction 연산은 합산입니다. `.sum()` 함수를 사용하여 **전체 텐서**를 줄이거 나 `dim` 인수를 사용하여 텐서의 **한 차원만**을 줄일 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "LlmsYJWUE2r3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23504d02-859a-4c73-c000-fe76a35f6372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "\n",
            "Sum over entire tensor:\n",
            "tensor(21.)\n",
            "tensor(21.)\n",
            "\n",
            "Sum of each row:\n",
            "tensor([5., 7., 9.])\n",
            "tensor([5., 7., 9.])\n",
            "torch.Size([3])\n",
            "\n",
            "Sum of each column:\n",
            "tensor([ 6., 15.])\n",
            "tensor([ 6., 15.])\n",
            "torch.Size([2])\n"
          ]
        }
      ],
      "source": [
        "# Chunk 2.4.3.\n",
        "\n",
        "x = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]], dtype=torch.float32)\n",
        "print('Original tensor:')\n",
        "print(x)\n",
        "\n",
        "print('\\nSum over entire tensor:')\n",
        "print(torch.sum(x))\n",
        "print(x.sum())\n",
        "\n",
        "# We can sum over each row:\n",
        "# * 0번째 dimension에 대하여 모으기\n",
        "# * y[j] = sum_i x[i,j]\n",
        "print('\\nSum of each row:')\n",
        "y = torch.sum(x, dim=0)\n",
        "print(y)\n",
        "y = x.sum(dim=0)\n",
        "print(y)\n",
        "print(y.shape)\n",
        "\n",
        "# Sum over each column:\n",
        "# * 1번째 dimension에 대하여 모으기\n",
        "# * y[i] = sum_j x[i,j]\n",
        "print('\\nSum of each column:')\n",
        "y = torch.sum(x, dim=1)\n",
        "print(y)\n",
        "y = x.sum(dim=1)\n",
        "print(y)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzKio_3Quz5a"
      },
      "source": [
        "기타 유용한 reduction 연산에는 [`mean`](https://pytorch.org/docs/stable/torch.html#torch.mean), [`min`](https://pytorch.org/docs/stable/torch.html#torch.min), [`max`](https://pytorch.org/docs/stable/torch.html#torch.max) 가 있습니다. 사용 가능한 모든 reduction 연산의 전체 목록은 [문서에서](https://pytorch.org/docs/stable/torch.html#reduction-ops) 찾을 수 있습니다.\n",
        "\n",
        "일부 reduction 연산은 둘 이상의 값을 반환합니다. 예를 들어 'min'은 지정된 차원에 대한 최소값과 최소값이 발생하는 인덱스를 모두 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "TFD7aT54H4ik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f78ec3-73fc-4478-e5ab-1bb2fb64c8d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            "tensor([[2., 4., 3., 5.],\n",
            "        [3., 3., 5., 2.]]) torch.Size([2, 4])\n",
            "\n",
            "Overall minimum:  tensor(2.)\n",
            "\n",
            "Minimum along each column:\n",
            "values: tensor([2., 3., 3., 2.])\n",
            "idxs: tensor([0, 1, 0, 1])\n",
            "\n",
            "Minimum along each row:\n",
            "values: tensor([2., 2.])\n",
            "idxs: tensor([0, 3])\n"
          ]
        }
      ],
      "source": [
        "# Chunk 2.4.4.\n",
        "\n",
        "# 복붙\n",
        "\n",
        "x = torch.tensor([[2, 4, 3, 5], [3, 3, 5, 2]], dtype=torch.float32)\n",
        "print('Original tensor:')\n",
        "print(x, x.shape)\n",
        "\n",
        "# Finding the overall minimum only returns a single value\n",
        "print('\\nOverall minimum: ', x.min())\n",
        "\n",
        "# Compute the minimum along each column; we get both the value and location:\n",
        "# The minimum of the first column is 2, and it appears at index 0;\n",
        "# the minimum of the second column is 3 and it appears at index 1; etc\n",
        "col_min_vals, col_min_idxs = x.min(dim=0)\n",
        "print('\\nMinimum along each column:')\n",
        "print('values:', col_min_vals)\n",
        "print('idxs:', col_min_idxs)\n",
        "\n",
        "# Compute the minimum along each row; we get both the value and the minimum\n",
        "row_min_vals, row_min_idxs = x.min(dim=1)\n",
        "print('\\nMinimum along each row:')\n",
        "print('values:', row_min_vals)\n",
        "print('idxs:', row_min_idxs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFwYRESoFr4t"
      },
      "source": [
        "reduction 연산은 텐서의 순위를 *감소*시킵니다: 축소를 수행하는 차원이 출력 크기에서 제거됩니다. reduction 연산에 `keepdim=True`를 전달하면 지정된 차원이 제거되지 않습니다. 출력 텐서는 대신 해당 차원에서 1의 크기를 갖습니다.\n",
        "\n",
        "**다차원 텐서로 작업할 때 행과 열에 대해 생각하면 혼란스러울 수 있습니다.**# Chunk 2.4.1.; 대신 각 연산에서 생성될 크기에 대해 생각하는 것이 더 유용합니다.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "sjcAveyJFqm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557be3df-e88a-47fd-ee65-32146eab5a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 10, 3, 64, 64])\n",
            "torch.Size([128, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# Chunk 2.4.5.\n",
        "\n",
        "# Create a tensor of shape (128, 10, 3, 64, 64)\n",
        "x = torch.randn(128, 10, 3, 64, 64)\n",
        "print(x.shape)\n",
        "\n",
        "# Take the mean over dimension 1; shape is now (128, 3, 64, 64)\n",
        "x = x.mean(dim=1)\n",
        "# x[i,k,l,m] <- (1/10) * sum_j x[i,j,k,l,m]\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "s-FkUkkAhWRn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bad9c8b-83be-4a5c-d337-0cf6ca5a987c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 64])\n"
          ]
        }
      ],
      "source": [
        "# Take the sum over dimension 2; shape is now (128, 3, 64)\n",
        "x = x.sum(dim=2)\n",
        "# x[i,k,m] <- sum_l x[i,k,l,m]\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "-tlMpYL3hWRn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daa011e5-0fac-4a56-a06e-7ac489f92774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1, 64])\n"
          ]
        }
      ],
      "source": [
        "# Take the mean over dimension 1, but keep the dimension from being eliminated\n",
        "# by passing keepdim=True; shape is now (128, 1, 64)\n",
        "x = x.mean(dim=1, keepdim=True)\n",
        "# x[i,0,m] <- sum_k x[i,k,m]\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = torch.tensor([[[1,2,3],[4,5,6]],[[-1,-2,-3],[-4,-5,-6]]])\n",
        "print(tmp)\n",
        "print(tmp.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w5_EFiddLhi",
        "outputId": "cd9cf934-b9da-4e35-844a-a883b442fc61"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1,  2,  3],\n",
            "         [ 4,  5,  6]],\n",
            "\n",
            "        [[-1, -2, -3],\n",
            "         [-4, -5, -6]]])\n",
            "torch.Size([2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp.sum(dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehzUUSxpd1l4",
        "outputId": "d9f7d100-12bd-4a43-b876-8a85517843c6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0],\n",
              "        [0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp.sum(dim=1)   #위아래로 sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vuFEjF8d3rI",
        "outputId": "9e347c71-805c-4966-b774-7e214430b8dc"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5,  7,  9],\n",
              "        [-5, -7, -9]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp.sum(dim=2)   #옆으로 sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQYOgm9heA65",
        "outputId": "788ae802-946c-42c4-a435-0b9c1a8730b9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  6,  15],\n",
              "        [ -6, -15]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRyLyXU2u29N"
      },
      "source": [
        "### Matrix operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DwjbapG6MM_"
      },
      "source": [
        "MATLAB과 달리 *는 행렬 곱셈이 아니라 원소별 곱셈입니다. (주. R과 동일) PyTorch는 다양한 유형의 벡터 및 행렬 곱을 계산하는 여러 선형대수 함수를 제공합니다. 가장 일반적으로 사용되는 것은 다음과 같습니다.\n",
        "\n",
        "- [`torch.dot`](https://pytorch.org/docs/1.1.0/torch.html#blas-and-lapack-operations): 벡터의 내적 계산\n",
        "- [`torch.mm`](https://pytorch.org/docs/1.1.0/torch.html#torch.mm): 행렬-행렬 곱 계산\n",
        "- [`torch.mv`](https://pytorch.org/docs/1.1.0/torch.html#torch.mv): 행렬-벡터 곱 계산\n",
        "- [`torch.addmm`](https://pytorch.org/docs/1.1.0/torch.html#torch.addmm) / [`torch.addmv`](https://pytorch.org/docs/1.1.0/torch.html#torch.addmv): 행렬-행렬 및 행렬-벡터 곱셈과 편향을 계산\n",
        "- [`torch.bmm`](https://pytorch.org/docs/1.1.0/torch.html#torch.addmv) / [`torch.baddmm`](https://pytorch.org/docs/1.1.0/torch.html#torch.baddbmm): 각각 `torch.mm` 및 `torch.addmm`의 Batched versions\n",
        "- [`torch.matmul`](https://pytorch.org/docs/1.1.0/torch.html#torch.matmul): 입력의 rank에 따라 다른 연산을 수행하는 일반 행렬 곱; 이것은 numpy의 `np.dot`와 유사합니다.\n",
        "\n",
        "사용 가능한 선형대수학 연산자의 전체 목록은 [문서에서](https://pytorch.org/docs/1.1.0/torch.html#blas-and-lapack-operations) 찾을 수 있습니다.\n",
        "\n",
        "다음은 `torch.dot`를 사용하여 내적을 계산하는 예입니다. 우리가 본 다른 수학 연산자와 마찬가지로 대부분의 선형 대수 연산자는 `torch` 모듈의 함수(예. `torch.dot(x,y)`)와 텐서의 인스턴스 메서드(예. `x .dot(y)`)에서 모두 사용 가능합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "TRUYW2as6ZCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dda5f6f-7956-4984-e4ae-9e9c1e808b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dot products:\n",
            "tensor(219.)\n",
            "tensor(219.)\n"
          ]
        }
      ],
      "source": [
        "# Chunk 2.4.8.\n",
        "\n",
        "v = torch.tensor([9,10], dtype=torch.float32)\n",
        "w = torch.tensor([11, 12], dtype=torch.float32)\n",
        "\n",
        "# Inner product of vectors\n",
        "print('Dot products:')\n",
        "print(torch.dot(v, w))\n",
        "print(v.dot(w))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN6FfqU9wFeG"
      },
      "source": [
        "## 2.5. Running on GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds6SDTbrwOc1"
      },
      "source": [
        "PyTorch의 가장 중요한 기능 중 하나는 GPU(그래픽 처리 장치)를 사용하여 텐서 연산을 가속화할 수 있다는 것입니다.\n",
        "\n",
        "PyTorch가 GPU를 사용하도록 세팅되었는지 쉽게 확인할 수 있습니다.\n",
        "\n",
        "텐서는 .to 메서드를 사용하여 모든 device로 이동할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "_RkoFEVVKWlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8c86d59-930e-4c51-cda0-4ff7b0b9db48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch can use GPUs!\n"
          ]
        }
      ],
      "source": [
        "# Chunk 2.6.1.\n",
        "\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print('PyTorch can use GPUs!')\n",
        "else:\n",
        "  print('PyTorch cannot use GPUs.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i_5n_XuKr5k"
      },
      "source": [
        "(주. CUDA: GPU에서의 연산을 산업표준 언어(이를테면 C)로 구현하도록 돕는 기술 중 하나. CUDA는 엔비디아가 개발해오고 있으며, CUDA를 사용하려면 엔비디아의 GPU 하드웨어가 필요하다. [위키백과](https://ko.wikipedia.org/wiki/CUDA))\n",
        "\n",
        "Colab에서 GPU 활성화하는 법: 런타임 -> 런타임 유형 변경 -> 하드웨어 가속기 -> GPU.\n",
        "\n",
        "이로 인해 Colab 런타임이 다시 시작될 수 있으므로 다음 셀에서 torch를 다시 import 합니다.\n",
        "\n",
        "우리는 이미 PyTorch 텐서가 데이터 타입을 지정하는 `dtype` 속성을 가지고 있음을 보았습니다. 모든 PyTorch 텐서는 CPU 또는 CUDA(NVidia GPU의 경우)와 같이 텐서가 저장된 device를 지정하는 `device` 속성도 있습니다. CUDA device의 텐서는 자동으로 해당 device를 사용하여 모든 연산을 가속화합니다.\n",
        "\n",
        "데이터 타입과 마찬가지로 [`.to()`](https://pytorch.org/docs/1.1.0/tensors.html#torch.Tensor.to) 메서드를 사용하여 텐서의 device를 변경할 수 있습니다. 또한 `.cuda()` 및 `.cpu()` 메서드를 사용하여 CPU와 GPU 간에 텐서를 이동할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "D03s614dMCvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "347b41e6-f41e-4ebe-cbef-b91a068892ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x0 device: cpu\n",
            "x1 device: cuda:0\n",
            "x2 device: cuda:0\n",
            "x3 device: cpu\n",
            "x4 device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Chunk 2.6.2.\n",
        "\n",
        "# Construct a tensor on the CPU\n",
        "x0 = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "print('x0 device:', x0.device)\n",
        "\n",
        "# Move it to the GPU using .to()\n",
        "x1 = x0.to('cuda')\n",
        "print('x1 device:', x1.device)\n",
        "\n",
        "# Move it to the GPU using .cuda()\n",
        "x2 = x0.cuda()\n",
        "print('x2 device:', x2.device)\n",
        "\n",
        "# 아래부터 복붙\n",
        "# Move it back to the CPU using .to()\n",
        "x3 = x1.to('cpu')\n",
        "print('x3 device:', x3.device)\n",
        "\n",
        "# Move it back to the CPU using .cpu()\n",
        "x4 = x2.cpu()\n",
        "print('x4 device:', x4.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-TDxICdOmJo"
      },
      "source": [
        "GPU에서 대규모 텐서 연산을 수행하는 것이 CPU에서 동등한 연산을 실행하는 것보다 **훨씬 빠릅니다**.\n",
        "\n",
        "CPU와 GPU에서 (10000, 10000) 크기의 두 텐서를 추가하는 속도를 비교해봅시다.\n",
        "\n",
        "(**GPU 코드는 CPU 코드와 비동기식으로 실행될 수 있으므로 GPU에서 작업 속도를 측정할 때 `torch.cuda.synchronize`를 사용하여 CPU와 GPU를 동기화하는 것이 중요합니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "GW14ZF-_PK7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d671942f-eaad-4226-d762-ebbafba4fa42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max difference between c_gpu and c_cpu: 0.0\n",
            "CPU time: 258.91 ms\n",
            "GPU time: 51.73 ms\n",
            "GPU speedup: 5.00 x\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "a_cpu = torch.randn(10000, 10000, dtype=torch.float32)\n",
        "b_cpu = torch.randn(10000, 10000, dtype=torch.float32)\n",
        "\n",
        "a_gpu = a_cpu.cuda()\n",
        "b_gpu = b_cpu.cuda()\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "t0 = time.time()\n",
        "c_cpu = a_cpu + b_cpu\n",
        "t1 = time.time()\n",
        "c_gpu = a_gpu + b_gpu\n",
        "torch.cuda.synchronize()\n",
        "t2 = time.time()\n",
        "\n",
        "# Check that they computed the same thing\n",
        "diff = (c_gpu.cpu() - c_cpu).abs().max().item()\n",
        "print('Max difference between c_gpu and c_cpu:', diff)\n",
        "\n",
        "cpu_time = 1000.0 * (t1 - t0)\n",
        "gpu_time = 1000.0 * (t2 - t1)\n",
        "print('CPU time: %.2f ms' % cpu_time)\n",
        "print('GPU time: %.2f ms' % gpu_time)\n",
        "print('GPU speedup: %.2f x' % (cpu_time / gpu_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HEAVPEwviYb"
      },
      "source": [
        "GPU에서 동일한 계산을 실행하는 것이 CPU에서보다 30배 이상 빠른 것을 볼 수 있습니다! (주. 테스트 결과 11배 정도 가속됨)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6. Loading CIFAR10"
      ],
      "metadata": {
        "id": "agp8CjJcjHV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "``torchvision`` 패키지를 이용하면, CIFAR10 데이터를 쉽게 불러올 수 있다."
      ],
      "metadata": {
        "id": "-hnAyV99mRC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "5XPMYGp8j3GU"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR10 데이터는 각각이 3x32x32로 이루어져 있으며, 아래의 코드를 이용해서 다운로드 한 뒤 및 trainloader 및 testloader에 저장하게 된다.\n",
        "\n",
        "* root : 저장위치\n",
        "* download : 다운로드 여부\n",
        "* transform :"
      ],
      "metadata": {
        "id": "CFWOsm4Gmd_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])    # 0~1 RGB 픽셀값 범위 => -0.5~0.5 => -1~1\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "-AywuA-yjy3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "570b64d7-4c3a-4b02-ceb3-259d1ff85dd0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 47946058.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset[0][0].shape  # 첫번째 이미지의 첫번째 성분\n",
        "# trainset[0] : tuple"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpWz-8DZloLK",
        "outputId": "8f0ded34-f91b-4851-a869-7f8664f8deb9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset[0][0]  # 이미지"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H7LuEgRmVD-",
        "outputId": "eab8bc0d-c757-44df-d079-9493c6a934e8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5373, -0.6627, -0.6078,  ...,  0.2392,  0.1922,  0.1608],\n",
              "         [-0.8745, -1.0000, -0.8588,  ..., -0.0353, -0.0667, -0.0431],\n",
              "         [-0.8039, -0.8745, -0.6157,  ..., -0.0745, -0.0588, -0.1451],\n",
              "         ...,\n",
              "         [ 0.6314,  0.5765,  0.5529,  ...,  0.2549, -0.5608, -0.5843],\n",
              "         [ 0.4118,  0.3569,  0.4588,  ...,  0.4431, -0.2392, -0.3490],\n",
              "         [ 0.3882,  0.3176,  0.4039,  ...,  0.6941,  0.1843, -0.0353]],\n",
              "\n",
              "        [[-0.5137, -0.6392, -0.6235,  ...,  0.0353, -0.0196, -0.0275],\n",
              "         [-0.8431, -1.0000, -0.9373,  ..., -0.3098, -0.3490, -0.3176],\n",
              "         [-0.8118, -0.9451, -0.7882,  ..., -0.3412, -0.3412, -0.4275],\n",
              "         ...,\n",
              "         [ 0.3333,  0.2000,  0.2627,  ...,  0.0431, -0.7569, -0.7333],\n",
              "         [ 0.0902, -0.0353,  0.1294,  ...,  0.1608, -0.5137, -0.5843],\n",
              "         [ 0.1294,  0.0118,  0.1137,  ...,  0.4431, -0.0745, -0.2784]],\n",
              "\n",
              "        [[-0.5059, -0.6471, -0.6627,  ..., -0.1529, -0.2000, -0.1922],\n",
              "         [-0.8431, -1.0000, -1.0000,  ..., -0.5686, -0.6078, -0.5529],\n",
              "         [-0.8353, -1.0000, -0.9373,  ..., -0.6078, -0.6078, -0.6706],\n",
              "         ...,\n",
              "         [-0.2471, -0.7333, -0.7961,  ..., -0.4510, -0.9451, -0.8431],\n",
              "         [-0.2471, -0.6706, -0.7647,  ..., -0.2627, -0.7333, -0.7333],\n",
              "         [-0.0902, -0.2627, -0.3176,  ...,  0.0980, -0.3412, -0.4353]]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset[0][1]   # 정답"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-TvIk5jmM6s",
        "outputId": "683ef75c-cf45-4b49-b4ec-48cbcb907001"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# functions to show an image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "metadata": {
        "id": "dxaan0X5j45n"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 코드를 이용해서 trainloader내의 하나의 mini-batch를 가져오게 된다.  \n",
        "* iter\n",
        "* next"
      ],
      "metadata": {
        "id": "EqX0OR1Lm0Lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)"
      ],
      "metadata": {
        "id": "knTXUsFCmy8G"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape"
      ],
      "metadata": {
        "id": "30HltI4Gl04s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c02df96-ac80-4eba-c1aa-ffba01056995"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "id": "3jgr-vsOl7xv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f348405-fd2d-4df3-91fd-db1c8427179f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))"
      ],
      "metadata": {
        "id": "x9dXxx4wlzJU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "39de9191-a5e6-49b5-cdc3-92edafd152a8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "metadata": {
        "id": "CLarXDOLlPc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "190faed7-d324-441d-c119-79a23354b9ab"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  cat  deer   car   car\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}